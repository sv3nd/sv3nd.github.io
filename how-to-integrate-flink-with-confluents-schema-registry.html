<!DOCTYPE html>
<html lang="en">
	<head>
		<link href="http://gmpg.org/xfn/11" rel="profile">
		<meta http-equiv="X-UA-Compatible" content="IE=edge">
		<meta http-equiv="content-type" content="text/html; charset=utf-8">

		<!-- Enable responsiveness on mobile devices-->
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

		<title>Svend Vanderveken</title>

		<!-- CSS -->
		<link href="//fonts.googleapis.com/" rel="dns-prefetch">
		<link href="//fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic|Abril+Fatface|PT+Sans:400,400italic,700&amp;subset=latin,latin-ext" rel="stylesheet">

		<link rel="stylesheet" href="https://sv3nd.github.io/theme/css/poole.css" />
		<link rel="stylesheet" href="https://sv3nd.github.io/theme/css/hyde.css" />
		<link rel="stylesheet" href="https://sv3nd.github.io/theme/css/syntax.css" />
		<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">

		<!-- RSS -->
		<link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
	<script type="text/javascript">
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
 			(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
 			m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
 			})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
			ga('create', 'UA-101598127-1', 'auto');
			ga('send', 'pageview');
	</script>
	</head>

	<body class="theme-base-0d">
<div class="sidebar">
	<div class="container sidebar-sticky">
		<div class="sidebar-about">

			<h1>
				<a href="/">
					<img class="profile-picture" src="https://sv3nd.github.io/images/blog/svend.jpg">
					Svend Vanderveken
				</a>
			</h1>
			<p class="lead"></p>
			<p class="lead">I am a freelance Data Engineer, I focus on scalable data processing pipelines based on Spark, Kafka, Cassandra... I love to code, preferably in Scala, Python and SQL. </p>
			<p></p>
		</div>
		<nav class="sidebar-nav">
					<a class="sidebar-nav-item" href="https://github.com/sv3nd">
						<i class="fa fa-github"></i>
					</a>
					<a class="sidebar-nav-item" href="https://twitter.com/svend_x4f">
						<i class="fa fa-twitter"></i>
					</a>
					<a class="sidebar-nav-item" href="https://be.linkedin.com/in/vanderveken">
						<i class="fa fa-linkedin"></i>
					</a>
					<a class="sidebar-nav-item" href="http://stackoverflow.com/users/3318335/svend">
						<i class="fa fa-stack-overflow"></i>
					</a>
			<a class="sidebar-nav-item" href="">
				<i class="fa fa-feed"></i>
			</a>
		</nav>
	</div>
</div>		<div class="content container">
<div class="post">
	<h1 class="post-title">How to integrate Flink with Confluent's schema registry</h1>
	<span class="post-date">Fri 30 June 2017</span>
	<p>This post illustrates how to use Confluent's Avro serializer in order to let a Flink program consume and produce avro messages through Kafka while keeping track of the Avro Schemas in Confluent's schema registry. This can be interresting if the messages are pumped into or out of Kafka with Kafka Connect, Kafka Streams, or just with anything else also integrated with the schema registry.</p>
<p>This has been written with the following dependencies in mind: </p>
<div class="highlight"><pre><span></span><span class="n">libraryDependencies</span> <span class="o">++=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">&quot;org.apache.flink&quot;</span> <span class="o">%%</span> <span class="s">&quot;flink-scala&quot;</span> <span class="o">%</span> <span class="s">&quot;1.3.1&quot;</span> <span class="o">%</span> <span class="s">&quot;provided&quot;</span><span class="o">,</span>
  <span class="s">&quot;org.apache.flink&quot;</span> <span class="o">%%</span> <span class="s">&quot;flink-streaming-scala&quot;</span> <span class="o">%</span> <span class="s">&quot;1.3.1&quot;</span> <span class="o">%</span> <span class="s">&quot;provided&quot;</span><span class="o">,</span>
  <span class="s">&quot;org.apache.flink&quot;</span> <span class="o">%%</span> <span class="s">&quot;flink-connector-kafka-0.10&quot;</span> <span class="o">%</span> <span class="s">&quot;1.3.1&quot;</span><span class="o">,</span>

  <span class="s">&quot;io.confluent&quot;</span> <span class="o">%</span> <span class="s">&quot;kafka-avro-serializer&quot;</span> <span class="o">%</span> <span class="s">&quot;3.2.2&quot;</span><span class="o">)</span>
</pre></div>


<h2>Confluent's schema registry library</h2>
<p>Confluent has published their version of an <a href="https://github.com/confluentinc/schema-registry/tree/3.2.1-post/avro-serializer">Avro Serializer</a> which automatically (and idempotently) registers the Avro schema into the schema registry when performing serialization (as <a href="https://github.com/confluentinc/schema-registry/blob/3.2.1-post/avro-serializer/src/main/java/io/confluent/kafka/serializers/AbstractKafkaAvroSerializer.java#L72">visible here</a>). The convention they use is simply to declare 2 <em>subjects</em> within the registry for each kafka topic, called <em>&lt;topic-name>-value</em> and <em>&lt;topic-name>-key</em> and put the schema there. This allows the de-serializer to <a href="https://github.com/confluentinc/schema-registry/blob/3.2.1-post/avro-serializer/src/main/java/io/confluent/kafka/serializers/AbstractKafkaAvroDeserializer.java#L121">retrieve the schema when needed</a>.</p>
<h2>Flink Kafka consumer</h2>
<p>There are various aspects to tackle when adding a Kafka consumer as a stream source to Flink. The one we're focusing on here is <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/dev/connectors/kafka.html#the-deserializationschema">the deserializations schema</a>. This class is the place where we can specify to Flink how handle the <code>byte[]</code> consumed from Kafka, so all we have to do is to plug there Confluent's schema-registry aware Avro deserializer. </p>
<p>It goes like this: </p>
<div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">io.confluent.kafka.serializers.</span><span class="o">{</span><span class="nc">AbstractKafkaAvroSerDeConfig</span><span class="o">,</span> <span class="nc">KafkaAvroDeserializer</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.avro.generic.GenericRecord</span>
<span class="k">import</span> <span class="nn">org.apache.flink.api.common.typeinfo.TypeInformation</span>
<span class="k">import</span> <span class="nn">org.apache.flink.api.java.typeutils.TypeExtractor</span>
<span class="k">import</span> <span class="nn">org.apache.flink.streaming.util.serialization.KeyedDeserializationSchema</span>

<span class="k">case</span> <span class="k">class</span> <span class="nc">KafkaKV</span><span class="o">(</span><span class="n">key</span><span class="k">:</span> <span class="kt">GenericRecord</span><span class="o">,</span> <span class="n">value</span><span class="k">:</span> <span class="kt">GenericRecord</span><span class="o">)</span>

<span class="k">class</span> <span class="nc">ConfluentRegistryDeserialization</span><span class="o">(</span><span class="n">topic</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">schemaRegistryUrl</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span> 
      <span class="k">extends</span> <span class="nc">KeyedDeserializationSchema</span><span class="o">[</span><span class="kt">KafkaKV</span><span class="o">]</span> <span class="o">{</span>

  <span class="c1">// Flink needs the serializer to be serializable =&gt; this &quot;@transient lazy val&quot; does the trick</span>
  <span class="nd">@transient</span> <span class="k">lazy</span> <span class="k">val</span> <span class="n">valueDeserializer</span> <span class="k">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">deserializer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">KafkaAvroDeserializer</span><span class="o">()</span>
    <span class="n">deserializer</span><span class="o">.</span><span class="n">configure</span><span class="o">(</span>
      <span class="c1">// other schema-registry configuration parameters can be passed, see the configure() code </span>
      <span class="c1">// for details (among other things, schema cache size)</span>
      <span class="nc">Map</span><span class="o">(</span><span class="nc">AbstractKafkaAvroSerDeConfig</span><span class="o">.</span><span class="nc">SCHEMA_REGISTRY_URL_CONFIG</span> <span class="o">-&gt;</span> <span class="n">schemaRegistryUrl</span><span class="o">).</span><span class="n">asJava</span><span class="o">,</span> 
      <span class="kc">false</span><span class="o">)</span>
    <span class="n">deserializer</span>
  <span class="o">}</span>

  <span class="nd">@transient</span> <span class="k">lazy</span> <span class="k">val</span> <span class="n">keyDeserializer</span> <span class="k">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">deserializer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">KafkaAvroDeserializer</span><span class="o">()</span>
    <span class="n">deserializer</span><span class="o">.</span><span class="n">configure</span><span class="o">(</span>
      <span class="nc">Map</span><span class="o">(</span><span class="nc">AbstractKafkaAvroSerDeConfig</span><span class="o">.</span><span class="nc">SCHEMA_REGISTRY_URL_CONFIG</span> <span class="o">-&gt;</span> <span class="n">schemaRegistryUrl</span><span class="o">).</span><span class="n">asJava</span><span class="o">,</span> 
      <span class="kc">true</span><span class="o">)</span>
    <span class="n">deserializer</span>
  <span class="o">}</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">isEndOfStream</span><span class="o">(</span><span class="n">nextElement</span><span class="k">:</span> <span class="kt">KafkaKV</span><span class="o">)</span><span class="k">:</span> <span class="kt">Boolean</span> <span class="o">=</span> <span class="kc">false</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">deserialize</span><span class="o">(</span><span class="n">messageKey</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Byte</span><span class="o">],</span> <span class="n">message</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Byte</span><span class="o">],</span> 
                           <span class="n">topic</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">partition</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span> <span class="n">offset</span><span class="k">:</span> <span class="kt">Long</span><span class="o">)</span><span class="k">:</span> <span class="kt">KafkaKV</span> <span class="o">=</span> <span class="o">{</span>

    <span class="k">val</span> <span class="n">key</span> <span class="k">=</span> <span class="n">keyDeserializer</span><span class="o">(</span><span class="n">topic</span><span class="o">,</span> <span class="n">messageKey</span><span class="o">).</span><span class="n">asInstanceOf</span><span class="o">[</span><span class="kt">GenericRecord</span><span class="o">]</span>
    <span class="k">val</span> <span class="n">value</span> <span class="k">=</span> <span class="n">valueDeserializer</span><span class="o">.</span><span class="n">deserialize</span><span class="o">(</span><span class="n">topic</span><span class="o">,</span> <span class="n">message</span><span class="o">).</span><span class="n">asInstanceOf</span><span class="o">[</span><span class="kt">GenericRecord</span><span class="o">]</span>

    <span class="nc">KafkaKV</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="n">value</span><span class="o">)</span>
  <span class="o">}</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">getProducedType</span><span class="k">:</span> <span class="kt">TypeInformation</span><span class="o">[</span><span class="kt">KafkaKV</span><span class="o">]</span> <span class="k">=</span> 
      <span class="nc">TypeExtractor</span><span class="o">.</span><span class="n">getForClass</span><span class="o">(</span><span class="n">classOf</span><span class="o">[</span><span class="kt">KafkaKV</span><span class="o">])</span>
<span class="o">}</span>
</pre></div>


<p>Once this is in place, we can use it to create a Flink Kafka source as follows: </p>
<div class="highlight"><pre><span></span>  <span class="k">import</span> <span class="nn">org.apache.flink.api.scala._</span>
  <span class="k">import</span> <span class="nn">org.apache.flink.streaming.api.scala.StreamExecutionEnvironment</span>
  <span class="k">import</span> <span class="nn">org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer010</span>

  <span class="o">[</span><span class="kt">...</span><span class="o">]</span>

  <span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>

  <span class="k">val</span> <span class="n">kafkaConsumerConfig</span> <span class="k">=</span> <span class="o">...</span>

  <span class="k">val</span> <span class="n">kafkaStream</span> <span class="k">=</span> <span class="n">env</span>
    <span class="o">.</span><span class="n">addSource</span><span class="o">(</span>
      <span class="k">new</span> <span class="nc">FlinkKafkaConsumer010</span><span class="o">[</span><span class="kt">KafkaKV</span><span class="o">](</span>
        <span class="s">&quot;someInboundTopic&quot;</span><span class="o">,</span>
        <span class="k">new</span> <span class="nc">ConfluentRegistryDeserialization</span><span class="o">(</span><span class="s">&quot;someInboundTopic&quot;</span><span class="o">,</span> <span class="s">&quot;http://localhost:8081&quot;</span><span class="o">),</span>
        <span class="n">kafkaConsumerConfig</span>
        <span class="o">)</span>
      <span class="o">)</span>
    <span class="o">)</span>
</pre></div>


<h2>Flink Kafka producer</h2>
<p>This is exactly the same story: in order to be able to produce avro messages into Kafka with Flink while automatically registering their schema in the registry, all we have to do is provide a Flink serializer that is essentially an adapter to Confluent's Avro serializer. </p>
<div class="highlight"><pre><span></span><span class="k">type</span> <span class="kt">KafkaKey</span> <span class="o">=</span> <span class="nc">String</span>
<span class="k">case</span> <span class="k">class</span> <span class="nc">SomePojo</span><span class="o">(</span><span class="n">foo</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">bar</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span>

<span class="k">class</span> <span class="nc">ConfluentRegistrySerialization</span><span class="o">(</span><span class="n">topic</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">schemaRegistryUrl</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span> 
        <span class="k">extends</span> <span class="nc">KeyedSerializationSchema</span><span class="o">[(</span><span class="kt">KafkaKey</span>, <span class="kt">SomePojo</span><span class="o">)]{</span>

  <span class="nd">@transient</span> <span class="k">lazy</span> <span class="k">val</span> <span class="n">valueSerializer</span> <span class="k">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">serializer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">KafkaAvroSerializer</span><span class="o">()</span>
    <span class="n">serializer</span><span class="o">.</span><span class="n">configure</span><span class="o">(</span>
      <span class="nc">Map</span><span class="o">(</span><span class="nc">AbstractKafkaAvroSerDeConfig</span><span class="o">.</span><span class="nc">SCHEMA_REGISTRY_URL_CONFIG</span> <span class="o">-&gt;</span> <span class="n">schemaRegistryUrl</span><span class="o">).</span><span class="n">asJava</span><span class="o">,</span>
      <span class="kc">false</span><span class="o">)</span>
    <span class="n">serializer</span>
  <span class="o">}</span>

  <span class="nd">@transient</span> <span class="k">lazy</span> <span class="k">val</span> <span class="n">keySerializer</span> <span class="k">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">serializer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">KafkaAvroSerializer</span><span class="o">()</span>
    <span class="n">serializer</span><span class="o">.</span><span class="n">configure</span><span class="o">(</span>
      <span class="nc">Map</span><span class="o">(</span><span class="nc">AbstractKafkaAvroSerDeConfig</span><span class="o">.</span><span class="nc">SCHEMA_REGISTRY_URL_CONFIG</span> <span class="o">-&gt;</span> <span class="n">schemaRegistryUrl</span><span class="o">).</span><span class="n">asJava</span><span class="o">,</span>
      <span class="kc">true</span><span class="o">)</span>
    <span class="n">serializer</span>
  <span class="o">}</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">serializeKey</span><span class="o">(</span><span class="n">keyedMessages</span><span class="k">:</span> <span class="o">(</span><span class="kt">KafkaKey</span><span class="o">,</span> <span class="kt">SomePojo</span><span class="o">))</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Byte</span><span class="o">]</span> <span class="k">=</span>
    <span class="n">keySerializer</span><span class="o">.</span><span class="n">serialize</span><span class="o">(</span><span class="n">topic</span><span class="o">,</span> <span class="n">keyedMessages</span><span class="o">.</span><span class="n">_1</span><span class="o">)</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">getTargetTopic</span><span class="o">(</span><span class="n">element</span><span class="k">:</span> <span class="o">(</span><span class="kt">KafkaKey</span><span class="o">,</span> <span class="kt">SomePojo</span><span class="o">))</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="n">topic</span>

  <span class="k">override</span> <span class="k">def</span> <span class="n">serializeValue</span><span class="o">(</span><span class="n">keyedMessages</span><span class="k">:</span> <span class="o">(</span><span class="kt">KafkaKey</span><span class="o">,</span> <span class="kt">SomePojo</span><span class="o">))</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Byte</span><span class="o">]</span> <span class="k">=</span>
     <span class="n">valueSerializer</span><span class="o">.</span><span class="n">serialize</span><span class="o">(</span><span class="n">topic</span><span class="o">,</span> <span class="n">keyedMessages</span><span class="o">.</span><span class="n">_2</span><span class="o">)</span>
<span class="o">}</span>
</pre></div>


<p>And again, once this serialization adapter is there, all we have to do is </p>
<div class="highlight"><pre><span></span>  <span class="k">val</span> <span class="n">kafkaProducerConfig</span> <span class="k">=</span> <span class="o">...</span>

  <span class="k">val</span> <span class="n">someStream</span> <span class="k">=</span> <span class="n">kafkaStream</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">blabla</span><span class="o">)...</span>

  <span class="nc">FlinkKafkaProducer010</span><span class="o">.</span><span class="n">writeToKafkaWithTimestamps</span><span class="o">(</span>
    <span class="n">someStream</span><span class="o">.</span><span class="n">javaStream</span><span class="o">,</span>
    <span class="s">&quot;destinationTopic&quot;</span><span class="o">,</span>
    <span class="k">new</span> <span class="nc">AvroRegistrySerialization</span><span class="o">(</span><span class="s">&quot;destinationTopic&quot;</span><span class="o">,</span> <span class="s">&quot;http://localhost:8081&quot;</span><span class="o">),</span>
    <span class="n">kafkaProducerConfig</span><span class="o">)))</span>
</pre></div>


<p>That's about it :) </p>
	<div id="disqus_thread"></div>
		<script type="text/javascript">
			var disqus_shortname = 'svend-blog';
			(function() {
	 			var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	 			dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	 			(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	 		})();
		</script>
	<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
</div>
		</div>
	</body>
</html>