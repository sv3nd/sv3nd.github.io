<!DOCTYPE html>
<html lang="en">
	<head>
		<link href="http://gmpg.org/xfn/11" rel="profile">
		<meta http-equiv="X-UA-Compatible" content="IE=edge">
		<meta http-equiv="content-type" content="text/html; charset=utf-8">

		<!-- Enable responsiveness on mobile devices-->
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

		<title>Svend Vanderveken - Articles by Svend Vanderveken</title>

		<!-- CSS -->
		<link href="//fonts.googleapis.com/" rel="dns-prefetch">
		<link href="//fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic|Abril+Fatface|PT+Sans:400,400italic,700&amp;subset=latin,latin-ext" rel="stylesheet">

		<link rel="stylesheet" href="https://svend.kelesia.com/theme/css/poole.css" />
		<link rel="stylesheet" href="https://svend.kelesia.com/theme/css/hyde.css" />
		<link rel="stylesheet" href="https://svend.kelesia.com/theme/css/syntax.css" />
		<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">

		<!-- RSS -->
		<link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
	<script type="text/javascript">
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
 			(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
 			m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
 			})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
			ga('create', 'UA-101598127-1', 'auto');
			ga('send', 'pageview');
	</script>
	</head>

	<body class="theme-base-0d">
<div class="sidebar">
	<div class="container sidebar-sticky">
		<div class="sidebar-about">

			<h1>
				<a href="/">
					<img class="profile-picture" src="https://svend.kelesia.com/images/blog/svend.jpg">
					Svend Vanderveken
				</a>
			</h1>
			<p class="lead"></p>
			<p class="lead">I am a freelance data engineer, I currently focus on streaming architectures, Kafka, Scala, Python, SQL,... </p>
			<p></p>
		</div>
		<nav class="sidebar-nav">
					<a class="sidebar-nav-item" href="https://github.com/sv3ndk">
						<i class="fa fa-github"></i>
					</a>
					<a class="sidebar-nav-item" href="https://twitter.com/sv3ndk">
						<i class="fa fa-twitter"></i>
					</a>
					<a class="sidebar-nav-item" href="https://be.linkedin.com/in/vanderveken">
						<i class="fa fa-linkedin"></i>
					</a>
					<a class="sidebar-nav-item" href="http://stackoverflow.com/users/3318335/svend">
						<i class="fa fa-stack-overflow"></i>
					</a>
			<a class="sidebar-nav-item" href="">
				<i class="fa fa-feed"></i>
			</a>
		</nav>
	</div>
</div>		<div class="content container">
	<div class="posts">
			<div class="post">
				<h1 class="post-title" href="https://svend.kelesia.com/one-to-many-kafka-streams-ktable-join.html#one-to-many-kafka-streams-ktable-join">
					<a href="https://svend.kelesia.com/one-to-many-kafka-streams-ktable-join.html#one-to-many-kafka-streams-ktable-join">One-to-many Kafka Streams Ktable join</a>
				</h1>
				<span class="post-date">Tue 30 April 2019</span>
				<p>
					<p>Kafka Streams is a lightweight data processing library for Kafka. It's build on top of the Kafka consumer/producer APIs and provides higher level abstractions like streams and tables that can be joined and grouped with some flexibility. </p>
<p>One current limitation is the lack of non-key table join, i.e. impossibility to join 2 tables on something else than their primary key. </p>
<p>This post discusses approaches to work around this limitation. </p>
<p>TLDR: </p>
<ul>
<li>For now, use composite keys in a state store and query it with a range scan. </li>
<li>Alternatively, wait for (or contribute to) KIP-213.</li>
</ul>
<p>An example implementation of my …</p>
				</p>
				<a class="read-more" href="one-to-many-kafka-streams-ktable-join.html">Continue reading »</a>
			</div>
			<div class="post">
				<h1 class="post-title" href="https://svend.kelesia.com/a-commented-kafka-configuration.html#a-commented-kafka-configuration">
					<a href="https://svend.kelesia.com/a-commented-kafka-configuration.html#a-commented-kafka-configuration">A commented Kafka configuration</a>
				</h1>
				<span class="post-date">Tue 19 December 2017</span>
				<p>
					<p>Diving into Kafka configuration is a beautiful journey into its features. </p>
<p>As a preparation for a production deployment of Kafka 0.11, I gathered a set of comments on what I think are some interesting parameters. All this amazing wisdom is mostly extracted from the few resources mentioned at the end of this post. </p>
<h3>A grain of salt...</h3>
<p>This is all for information only, I honestly think most of the points below are relevant and correct, though mistakes and omissions are likely present here and there. </p>
<p>You should not apply any of this blindly to your production environment and hope …</p>
				</p>
				<a class="read-more" href="a-commented-kafka-configuration.html">Continue reading »</a>
			</div>
			<div class="post">
				<h1 class="post-title" href="https://svend.kelesia.com/event-time-low-latency-joins-with-kafka-streams.html#event-time-low-latency-joins-with-kafka-streams">
					<a href="https://svend.kelesia.com/event-time-low-latency-joins-with-kafka-streams.html#event-time-low-latency-joins-with-kafka-streams">Event time low-latency joins with Kafka Streams</a>
				</h1>
				<span class="post-date">Sun 17 September 2017</span>
				<p>
					<p>This post attempts to illustrate the difficulty of performing an event-time join between two time series with a stream processing framework. It also describes one solution based on Kafka Streams 0.11.0.0.</p>
<p>An event-time join is an attempt to join two time series while taking into account the timestamps. More precisely, for each event from the first time series, it looks up the latest event from the other that occurred before it. This blog post is based on Kafka Stream although I found the original idea in this <a href="http://training.data-artisans.com/exercises/eventTimeJoin.html">Flink tutorial</a>, where the idea of event-time join is very …</p>
				</p>
				<a class="read-more" href="event-time-low-latency-joins-with-kafka-streams.html">Continue reading »</a>
			</div>
			<div class="post">
				<h1 class="post-title" href="https://svend.kelesia.com/how-to-integrate-flink-with-confluents-schema-registry.html#how-to-integrate-flink-with-confluents-schema-registry">
					<a href="https://svend.kelesia.com/how-to-integrate-flink-with-confluents-schema-registry.html#how-to-integrate-flink-with-confluents-schema-registry">How to integrate Flink with Confluent's schema registry</a>
				</h1>
				<span class="post-date">Fri 30 June 2017</span>
				<p>
					<p>This post illustrates how to use Confluent's Avro serializer in order to let a Flink program consume and produce avro messages through Kafka while keeping track of the Avro Schemas in Confluent's schema registry. This can be interresting if the messages are pumped into or out of Kafka with Kafka Connect, Kafka Streams, or just with anything else also integrated with the schema registry.</p>
<p><strong>Warning</strong>: As of now (Aug 2017), it turns out using Confluent's Avro deserializer as explained below is not ideal when deploying to FLink in standalone mode, because of the way caching is impemented on Avro level …</p>
				</p>
				<a class="read-more" href="how-to-integrate-flink-with-confluents-schema-registry.html">Continue reading »</a>
			</div>
			<div class="post">
				<h1 class="post-title" href="https://svend.kelesia.com/sending-avro-records-from-scala-to-azure-eventhub-over-amqp.html#sending-avro-records-from-scala-to-azure-eventhub-over-amqp">
					<a href="https://svend.kelesia.com/sending-avro-records-from-scala-to-azure-eventhub-over-amqp.html#sending-avro-records-from-scala-to-azure-eventhub-over-amqp">Sending Avro records from Scala to Azure eventhub over AMQP</a>
				</h1>
				<span class="post-date">Mon 26 June 2017</span>
				<p>
					<p>This post illustrates how to emit Avro records to Azure EventHub from scala in such a way that they are directly parsed by the other services of the Azure platform (e.g. Azure Stream Analytics). </p>
<p>There exists a Java API for communicating with Azure EventHub which is documented as part of the <a href="https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-java-get-started-send">azure documentation</a> and even made <a href="https://github.com/Azure/azure-event-hubs-java">open source on github</a> (things have changed at Microsoft...). That said, the most detailed documentation still seems to be based on the .NET API as manipulated with Visual Studio on Windows. Me being a Scala developer on a Mac, it took me a …</p>
				</p>
				<a class="read-more" href="sending-avro-records-from-scala-to-azure-eventhub-over-amqp.html">Continue reading »</a>
			</div>
	</div>
	<div class="pagination">

		<span class="pagination-item older">Newer</span>

		<span class="pagination-item newer"><a href="https://svend.kelesia.com/author/svend-vanderveken2.html">Older</a></span>
	</div>
		</div>
	</body>
</html>