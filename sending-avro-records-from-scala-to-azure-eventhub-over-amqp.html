<!DOCTYPE html>
<html lang="en">
	<head>
		<link href="http://gmpg.org/xfn/11" rel="profile">
		<meta http-equiv="X-UA-Compatible" content="IE=edge">
		<meta http-equiv="content-type" content="text/html; charset=utf-8">

		<!-- Enable responsiveness on mobile devices-->
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

		<title>Svend Vanderveken</title>

		<!-- CSS -->
		<link href="//fonts.googleapis.com/" rel="dns-prefetch">
		<link href="//fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic|Abril+Fatface|PT+Sans:400,400italic,700&amp;subset=latin,latin-ext" rel="stylesheet">

		<link rel="stylesheet" href="https://svend.kelesia.com/theme/css/poole.css" />
		<link rel="stylesheet" href="https://svend.kelesia.com/theme/css/hyde.css" />
		<link rel="stylesheet" href="https://svend.kelesia.com/theme/css/syntax.css" />
		<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">

		<!-- RSS -->
		<link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
	<script type="text/javascript">
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
 			(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
 			m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
 			})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
			ga('create', 'UA-101598127-1', 'auto');
			ga('send', 'pageview');
	</script>
	</head>

	<body class="theme-base-0d">
<div class="sidebar">
	<div class="container sidebar-sticky">
		<div class="sidebar-about">

			<h1>
				<a href="/">
					<img class="profile-picture" src="https://svend.kelesia.com/images/blog/svend.jpg">
					Svend Vanderveken
				</a>
			</h1>
			<p class="lead"></p>
			<p class="lead">I am a freelance Software developper, I currently focus on streaming architectures, Kafka, Scala, Python, SQL,... </p>
			<p></p>
		</div>
		<nav class="sidebar-nav">
					<a class="sidebar-nav-item" href="https://github.com/sv3ndk">
						<i class="fa fa-github"></i>
					</a>
					<a class="sidebar-nav-item" href="https://twitter.com/sv3ndk">
						<i class="fa fa-twitter"></i>
					</a>
					<a class="sidebar-nav-item" href="https://be.linkedin.com/in/vanderveken">
						<i class="fa fa-linkedin"></i>
					</a>
					<a class="sidebar-nav-item" href="http://stackoverflow.com/users/3318335/svend">
						<i class="fa fa-stack-overflow"></i>
					</a>
			<a class="sidebar-nav-item" href="">
				<i class="fa fa-feed"></i>
			</a>
		</nav>
	</div>
</div>		<div class="content container">
<div class="post">
	<h1 class="post-title">Sending Avro records from Scala to Azure eventhub over AMQP</h1>
	<span class="post-date">Mon 26 June 2017</span>
	<p>This post illustrates how to emit Avro records to Azure EventHub from scala in such a way that they are directly parsed by the other services of the Azure platform (e.g. Azure Stream Analytics). </p>
<p>There exists a Java API for communicating with Azure EventHub which is documented as part of the <a href="https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-java-get-started-send">azure documentation</a> and even made <a href="https://github.com/Azure/azure-event-hubs-java">open source on github</a> (things have changed at Microsoft...). That said, the most detailed documentation still seems to be based on the .NET API as manipulated with Visual Studio on Windows. Me being a Scala developer on a Mac, it took me a bit of experimentation to emit Avro messages to EventHub and have an Azure Stream Analytics job parse them correctly.</p>
<p>The steps below assume that you have access to the Azure portal and have created an EventHub namespace as well as an EventHub instance. If not, see the <a href="https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-create">Azure documentation here</a> for details.</p>
<p>I posted a fully working example <a href="https://github.com/svendx4f/avro-eventhub-scala-example">here on github</a>.</p>
<p>This post has been written with the following frawmework versions in mind:</p>
<ul>
<li>Avro 1.8.2</li>
<li>Azure EventHub SDK 0.14</li>
<li>Scala 2.11</li>
</ul>
<h2>Scala Avro record emitter</h2>
<p>In a nutshell, these are the few things to know when sending Avro to Azure EventHub: </p>
<ul>
<li>Each message sent to Azure is wrapped as part of an instance of <a href="https://github.com/Azure/azure-event-hubs-java/blob/dev/azure-eventhubs/src/main/java/com/microsoft/azure/eventhubs/EventData.java">EventData</a>, which also contains meta-data regarding the AMQP transmission.</li>
<li>The <code>byte[]</code> payload that we wrap inside an <code>EventData</code> instance should be a serialized Avro <em>file</em>, i.e. contain the Avro schema. This means we should use the Avro <a href="https://github.com/apache/avro/blob/branch-1.8/lang/java/avro/src/main/java/org/apache/avro/file/DataFileWriter.java">DataFileWriter</a> and serialize the output directly to an output stream to obtain the <code>byte[]</code>.</li>
<li>As for any Avro file, it is possible, and actually a very good idea, to put several avro records within the <code>EventData</code></li>
<li>Based on my experimentations, only uncompressed Avro records or records compressed with <a href="https://en.wikipedia.org/wiki/DEFLATE">Deflate</a> seem to be currently supported by Azure. During my tests, neither bzip2 nor Snappy could be read by the Stream Analytics job. </li>
</ul>
<p>Here is an extract of the scala code (see <a href="https://github.com/svendx4f/avro-eventhub-scala-example/blob/master/src/main/scala/org/svend/playground/EventHubAvroSender.scala">EventHubAvroSender on github</a> for details)</p>
<div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.microsoft.azure.eventhubs.</span><span class="o">{</span><span class="nc">EventData</span><span class="o">,</span> <span class="nc">EventHubClient</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.avro.file.</span><span class="o">{</span><span class="nc">Codec</span><span class="o">,</span> <span class="nc">CodecFactory</span><span class="o">,</span> <span class="nc">DataFileWriter</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.avro.generic.</span><span class="o">{</span><span class="nc">GenericDatumWriter</span><span class="o">,</span> <span class="nc">GenericRecord</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">scala.collection.JavaConverters._</span>

<span class="o">[</span><span class="kt">...</span><span class="o">]</span>

  <span class="k">val</span> <span class="n">ehClient</span> <span class="k">=</span> <span class="nc">EventHubClient</span><span class="o">.</span><span class="n">createFromConnectionStringSync</span><span class="o">(</span><span class="s">&quot;&lt;your eventhub connection string&gt;&quot;</span><span class="o">)</span>

  <span class="c1">// number of batches to send to the EventHub</span>
  <span class="k">val</span> <span class="n">batch_num</span> <span class="k">=</span> <span class="mi">10</span>

  <span class="c1">// number of EventData instances to put inside each batch</span>
  <span class="k">val</span> <span class="n">amqpMessagePerBatch</span> <span class="k">=</span> <span class="mi">15</span>

  <span class="c1">// number of avro records to bundle inside each AMQP message</span>
  <span class="k">val</span> <span class="n">userMessagesPerAmqp</span> <span class="k">=</span> <span class="mi">20</span>

  <span class="k">val</span> <span class="n">datumWriter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">GenericDatumWriter</span><span class="o">[</span><span class="kt">GenericRecord</span><span class="o">](</span><span class="nc">UserMessage</span><span class="o">.</span><span class="n">schema</span><span class="o">)</span>
  <span class="k">val</span> <span class="n">writer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DataFileWriter</span><span class="o">[</span><span class="kt">GenericRecord</span><span class="o">](</span><span class="n">datumWriter</span><span class="o">)</span>

  <span class="c1">// only Deflate seems to be compatible with Azure at the moment </span>
  <span class="n">writer</span><span class="o">.</span><span class="n">setCodec</span><span class="o">(</span><span class="nc">CodecFactory</span><span class="o">.</span><span class="n">deflateCodec</span><span class="o">(</span><span class="mi">9</span><span class="o">))</span>  
  <span class="c1">//writer.setCodec(CodecFactory.snappyCodec()) // not currently supported</span>
  <span class="c1">//writer.setCodec(CodecFactory.bzip2Codec())  // not currently supported</span>

  <span class="k">val</span> <span class="n">futures</span> <span class="k">=</span> <span class="o">(</span><span class="mi">1</span> <span class="n">to</span> <span class="n">batch_num</span><span class="o">)</span>
    <span class="o">.</span><span class="n">map</span><span class="o">{</span> <span class="n">batchid</span> <span class="k">=&gt;</span>

      <span class="c1">// list of EventData instances, each with a bunch of Avro records</span>
      <span class="k">val</span> <span class="n">eventHubMessages</span> <span class="k">=</span> <span class="o">(</span><span class="mi">1</span> <span class="n">to</span> <span class="n">amqpMessagePerBatch</span><span class="o">).</span><span class="n">map</span> <span class="o">{</span> <span class="k">_</span> <span class="k">=&gt;</span>

        <span class="k">val</span> <span class="n">bos</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ByteArrayOutputStream</span><span class="o">()</span>
        <span class="n">writer</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="nc">UserMessage</span><span class="o">.</span><span class="n">schema</span><span class="o">,</span> <span class="n">bos</span><span class="o">)</span>

        <span class="c1">// MessageGen.genMessage is a generator of random data</span>
        <span class="o">(</span><span class="mi">1</span> <span class="n">to</span> <span class="n">userMessagesPerAmqp</span><span class="o">).</span><span class="n">foreach</span> <span class="o">{</span> <span class="k">_</span> <span class="k">=&gt;</span> <span class="n">writer</span><span class="o">.</span><span class="n">append</span><span class="o">(</span><span class="nc">MessageGen</span><span class="o">.</span><span class="n">genMessage</span><span class="o">.</span><span class="n">toAvro</span><span class="o">)}</span>

        <span class="n">writer</span><span class="o">.</span><span class="n">close</span><span class="o">()</span>
        <span class="n">bos</span><span class="o">.</span><span class="n">close</span><span class="o">()</span>

        <span class="k">new</span> <span class="nc">EventData</span><span class="o">(</span><span class="n">bos</span><span class="o">.</span><span class="n">toByteArray</span><span class="o">)</span>
      <span class="o">}</span>

      <span class="n">println</span><span class="o">(</span><span class="s">s&quot;sending batch </span><span class="si">$batchid</span><span class="s">&quot;</span><span class="o">)</span>

      <span class="c1">// this sends a batch of EventData asynchronously and returns a Java Future</span>
      <span class="n">ehClient</span><span class="o">.</span><span class="n">send</span><span class="o">(</span><span class="n">eventHubMessages</span><span class="o">.</span><span class="n">asJava</span><span class="o">)</span>
    <span class="o">}</span>

  <span class="n">println</span><span class="o">(</span><span class="s">&quot;waiting for all futures before exiting...&quot;</span><span class="o">)</span>
  <span class="n">futures</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">get</span><span class="o">())</span>

  <span class="n">println</span><span class="o">(</span><span class="s">s&quot;ok, closing&quot;</span><span class="o">)</span>
  <span class="n">ehClient</span><span class="o">.</span><span class="n">close</span><span class="o">()</span>
</pre></div>


<p>Note that there are two batching mechanisms at play above: </p>
<ul>
<li>the set of <code>userMessagesPerAmqp</code> avro records we put inside each <code>EventData</code></li>
<li>the set of <code>amqpMessagePerBatch</code> AMQP messages that are sent as part of one AMQP batch</li>
</ul>
<p>I did not investigate what was the ideal combination of those two.</p>
<h2>Stream Analytics Job</h2>
<p>Azure stream analytics usage is described in <a href="https://docs.microsoft.com/en-us/azure/stream-analytics/">Azure documentation here</a>, they essentially let you execute an on-going <a href="https://docs.microsoft.com/en-us/azure/data-lake-analytics/data-lake-analytics-u-sql-get-started">U-SQL</a> query on data streaming out of an EventHub instance, IotHub instance or Blob Storage and forward the result to various outputs.</p>
<p><center><img src="images/sending-avro-events-to-azure-eventhub-from-scala/input-query-output.png"  width="400px" /> </center></p>
<p>All fields of the Avro schema are available in the query, so based on our example schema: </p>
<div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="nt">&quot;namespace&quot;</span><span class="p">:</span> <span class="s2">&quot;svend.playground.user&quot;</span><span class="p">,</span>
  <span class="nt">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;record&quot;</span><span class="p">,</span>
  <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;User&quot;</span><span class="p">,</span>
  <span class="nt">&quot;fields&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span><span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;user_id&quot;</span><span class="p">,</span>  <span class="nt">&quot;type&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;int&quot;</span><span class="p">,</span> <span class="s2">&quot;null&quot;</span><span class="p">]},</span>
    <span class="p">{</span><span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;mood&quot;</span><span class="p">,</span>  <span class="nt">&quot;type&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="s2">&quot;null&quot;</span><span class="p">]},</span>
    <span class="p">{</span><span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;message&quot;</span><span class="p">,</span> <span class="nt">&quot;type&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="s2">&quot;null&quot;</span>
  <span class="p">]</span>
<span class="p">}</span>
</pre></div>


<p>We can access each field as part of a query in the U-SQL editor of the Azure Stream Analytics Job: </p>
<p><center><img src="images/sending-avro-events-to-azure-eventhub-from-scala/example_query.png"  width="280px" /> </center></p>
<p>You might notice the presence of <code>EventEnqueuedUtcTime</code> in the query above, this is one of the supplementary fields that Azure EventHub adds to each received event, as <a href="https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-define-inputs">specified in the Azure documentation</a>:</p>
<p><center><img src="images/sending-avro-events-to-azure-eventhub-from-scala/supplementary_usql_fields.png"  width="500px" /> </center></p>
<p>Once everything is started, the Stream Analytics page on the Azure portal should start to show some process traffic: </p>
<p><center><img src="images/sending-avro-events-to-azure-eventhub-from-scala/analytics_traffic.png"  width="500px" /> </center></p>
	<div id="disqus_thread"></div>
		<script type="text/javascript">
			var disqus_shortname = 'svend-blog';
			(function() {
	 			var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	 			dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	 			(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	 		})();
		</script>
	<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
</div>
		</div>
	</body>
</html>